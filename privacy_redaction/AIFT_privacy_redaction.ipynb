{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4eelE3vl0Us2",
    "outputId": "1f223b79-dd14-43d7-ae58-b8492821da9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.37.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
      "Collecting datasets\n",
      "  Downloading datasets-2.17.1-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.7/536.7 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
      "Collecting multiprocess (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Installing collected packages: dill, multiprocess, datasets\n",
      "Successfully installed datasets-2.17.1 dill-0.3.8 multiprocess-0.70.16\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "XlqbxsEJ0dHm"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def get_device():\n",
    "    if torch.torch.cuda.is_available():\n",
    "        return torch.device('cuda:0')\n",
    "    else:\n",
    "        return torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Q9nUI9sT0g0J"
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModel\n",
    "from datasets import load_dataset, Dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mP2MtNQn0kMj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5cFPu7Rs2JuO"
   },
   "source": [
    "### DETECTING PERSONAL INFORMATION WITH NER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### USING DEFAULT PYTHAINLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LQLNKGXG0sRQ",
    "outputId": "4baf5333-d2bf-4c3c-81c2-45f8a6aa8c82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pythainlp in /usr/local/lib/python3.10/dist-packages (5.0.1)\n",
      "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from pythainlp) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->pythainlp) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->pythainlp) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->pythainlp) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->pythainlp) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install pythainlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "toVyXJtN0yyf"
   },
   "outputs": [],
   "source": [
    "from pythainlp.tag import NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "31qBnZVp0t3M",
    "outputId": "9eabf051-7139-490d-d180-8110de0612b6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ฉัน', 'O'),\n",
       " ('ชื่อ', 'O'),\n",
       " (' ', 'O'),\n",
       " ('นางสาว', 'B-PERSON'),\n",
       " ('มะลิ', 'I-PERSON'),\n",
       " ('วา', 'I-PERSON'),\n",
       " (' ', 'I-PERSON'),\n",
       " ('บุญ', 'I-PERSON'),\n",
       " ('สระ', 'I-PERSON'),\n",
       " ('ดี', 'I-PERSON'),\n",
       " (' ', 'O'),\n",
       " ('อาศัย', 'O'),\n",
       " ('อยู่', 'O'),\n",
       " ('ที่', 'O'),\n",
       " ('อําเภอ', 'B-LOCATION'),\n",
       " ('นาง', 'I-LOCATION'),\n",
       " ('รอง', 'I-LOCATION'),\n",
       " (' ', 'O'),\n",
       " ('จังหวัด', 'B-LOCATION'),\n",
       " ('บุรีรัมย์', 'I-LOCATION'),\n",
       " (' ', 'O'),\n",
       " ('อายุ', 'O'),\n",
       " (' ', 'O'),\n",
       " ('23', 'B-AGO'),\n",
       " (' ', 'I-AGO'),\n",
       " ('ปี', 'I-AGO'),\n",
       " (' ', 'O'),\n",
       " ('เพิ่ง', 'O'),\n",
       " ('เรียนจบ', 'O'),\n",
       " ('จาก', 'O'),\n",
       " (' ', 'O'),\n",
       " ('มหาวิทยาลั', 'B-ORGANIZATION'),\n",
       " ('ยขอนแก่น', 'I-ORGANIZATION'),\n",
       " (' ', 'O'),\n",
       " ('และ', 'O'),\n",
       " ('นี่', 'O'),\n",
       " ('คือ', 'O'),\n",
       " ('ข้อมูล', 'O'),\n",
       " ('ปลอม', 'O'),\n",
       " ('ชื่อ', 'O'),\n",
       " ('คน', 'O'),\n",
       " ('ไม่', 'O'),\n",
       " ('มี', 'O'),\n",
       " ('อยู่', 'O'),\n",
       " ('จริง', 'O'),\n",
       " (' ', 'O'),\n",
       " ('อายุ', 'O'),\n",
       " (' ', 'O'),\n",
       " ('23', 'B-AGO'),\n",
       " (' ', 'O'),\n",
       " ('ปี', 'I-AGO')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence=\"ฉันชื่อ นางสาวมะลิวา บุญสระดี อาศัยอยู่ที่อำเภอนางรอง จังหวัดบุรีรัมย์ อายุ 23 ปี เพิ่งเรียนจบจาก มหาวิทยาลัยขอนแก่น และนี่คือข้อมูลปลอมชื่อคนไม่มีอยู่จริง อายุ 23 ปี\"\n",
    "ner = NER()\n",
    "ner.tag(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IN CASE OF USING CUSTOM TOKENIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Y7qKBEwp01m1"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForTokenClassification\n",
    "from pythainlp.tokenize import word_tokenize # pip install pythainlp\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CTeXncng2gfb",
    "outputId": "2c69007b-c81c-4c5b-e9d0-35464f7e1510"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ฉัน', 'O'),\n",
       " ('ชื่อ', 'O'),\n",
       " (' ', 'O'),\n",
       " ('นางสาว', 'B-PERSON'),\n",
       " ('มะลิ', 'I-PERSON'),\n",
       " ('วา', 'I-PERSON'),\n",
       " (' ', 'I-PERSON'),\n",
       " ('บุญ', 'I-PERSON'),\n",
       " ('สระ', 'I-PERSON'),\n",
       " ('ดี', 'I-PERSON'),\n",
       " (' ', 'O'),\n",
       " ('อาศัย', 'O'),\n",
       " ('อยู่', 'O'),\n",
       " ('ที่', 'O'),\n",
       " ('อําเภอ', 'B-LOCATION'),\n",
       " ('นาง', 'I-LOCATION'),\n",
       " ('รอง', 'I-LOCATION'),\n",
       " (' ', 'O'),\n",
       " ('จังหวัด', 'B-LOCATION'),\n",
       " ('บุรีรัมย์', 'I-LOCATION'),\n",
       " (' ', 'O'),\n",
       " ('อายุ', 'O'),\n",
       " (' ', 'O'),\n",
       " ('23', 'B-AGO'),\n",
       " (' ', 'I-AGO'),\n",
       " ('ปี', 'I-AGO'),\n",
       " (' ', 'O'),\n",
       " ('เพิ่ง', 'O'),\n",
       " ('เรียนจบ', 'O'),\n",
       " ('จาก', 'O'),\n",
       " (' ', 'O'),\n",
       " ('มหาวิทยาลั', 'B-ORGANIZATION'),\n",
       " ('ยขอนแก่น', 'I-ORGANIZATION'),\n",
       " (' ', 'O'),\n",
       " ('และ', 'O'),\n",
       " ('นี่', 'O'),\n",
       " ('คือ', 'O'),\n",
       " ('ข้อมูล', 'O'),\n",
       " ('ปลอม', 'O'),\n",
       " ('ชื่อ', 'O'),\n",
       " ('คน', 'O'),\n",
       " ('ไม่', 'O'),\n",
       " ('มี', 'O'),\n",
       " ('อยู่', 'O'),\n",
       " ('จริง', 'O'),\n",
       " (' ', 'O'),\n",
       " ('อายุ', 'O'),\n",
       " (' ', 'O'),\n",
       " ('23', 'B-AGO'),\n",
       " (' ', 'O'),\n",
       " ('ปี', 'I-AGO')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name=\"pythainlp/thainer-corpus-v2-base-model\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(name)\n",
    "\n",
    "sentence=\"ฉันชื่อ นางสาวมะลิวา บุญสระดี อาศัยอยู่ที่อำเภอนางรอง จังหวัดบุรีรัมย์ อายุ 23 ปี เพิ่งเรียนจบจาก มหาวิทยาลัยขอนแก่น และนี่คือข้อมูลปลอมชื่อคนไม่มีอยู่จริง อายุ 23 ปี\"\n",
    "\n",
    "# replace space (\" \") with \"<_>\"\n",
    "sentence = sentence.replace(\" \", \"<_>\")\n",
    "# custom tokenizer can be used here\n",
    "cut=word_tokenize(sentence\n",
    "                  )\n",
    "inputs=tokenizer(cut,is_split_into_words=True,return_tensors=\"pt\")\n",
    "\n",
    "ids = inputs[\"input_ids\"]\n",
    "mask = inputs[\"attention_mask\"]\n",
    "# forward pass\n",
    "outputs = model(ids, attention_mask=mask)\n",
    "logits = outputs[0]\n",
    "\n",
    "predictions = torch.argmax(logits, dim=2)\n",
    "predicted_token_class = [model.config.id2label[t.item()] for t in predictions[0]]\n",
    "\n",
    "def fix_span_error(words,ner):\n",
    "    _ner = []\n",
    "    _ner=ner\n",
    "    _new_tag=[]\n",
    "    for i,j in zip(words,_ner):\n",
    "        #print(i,j)\n",
    "        i=tokenizer.decode(i)\n",
    "        if i.isspace() and j.startswith(\"B-\"):\n",
    "            j=\"O\"\n",
    "        if i=='' or i=='<s>' or i=='</s>':\n",
    "            continue\n",
    "        if i==\"<_>\":\n",
    "            i=\" \"\n",
    "        _new_tag.append((i,j))\n",
    "    return _new_tag\n",
    "\n",
    "ner_tag=fix_span_error(inputs['input_ids'][0],predicted_token_class)\n",
    "\n",
    "ner_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_FWJlAzK3bfL"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
